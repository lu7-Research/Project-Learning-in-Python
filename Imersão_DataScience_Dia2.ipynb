{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Imersão-DataScience-Dia2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "9DEJf4KV6ZEm"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lu7-Research/Project-Learning-in-Python/blob/main/Imers%C3%A3o_DataScience_Dia2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DEJf4KV6ZEm"
      },
      "source": [
        "# MACHINE LEARNING\n",
        "\n",
        "---\n",
        "![alt text](https://img-blog.csdnimg.cn/20200725231327252.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNjA2OTUz,size_16,color_FFFFFF,t_70)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEeR8-i6x-9Y"
      },
      "source": [
        "# AQUISIÇÃO DE DADOS\n",
        "# CARREGANDO LIBRARIES\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html\n",
        "\n",
        "# PRÉ-PROCESSAMENTO (PREPROCESSING) / ANÁLISE EXPLORATÓRIA\n",
        "iris.feature_names\n",
        "\n",
        "# DADOS QUE TEMOS\n",
        "iris.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrireER46hPX"
      },
      "source": [
        "iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXGH2q5LFjVS"
      },
      "source": [
        "### CLASSIFICAÇÃO VS. REGRESSÃO\n",
        "\n",
        "---\n",
        "![alt text](https://www.researchgate.net/profile/Yves_Matanga2/publication/326175998/figure/fig9/AS:644582983352328@1530691967314/Classification-vs-Regression.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkEL_IrTs8Gz"
      },
      "source": [
        "## Escolha algoritmo\n",
        "\n",
        "---\n",
        "\n",
        "![roadmap algoritmos](https://scikit-learn.org/stable/_static/ml_map.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIbFDwCs9vos"
      },
      "source": [
        "## INDICADORES DE DESEMPENHO\n",
        "\n",
        "---\n",
        "\n",
        "Para problemas de regressão utilizamos comumente o RMSE(raiz do erro quadrático médio), entre outras.\n",
        "<br><br>Para problemas de classificação, a matriz de confusão é uma alternativa bastante utilizada(Precisão, Acurácia, Recall, Score F1...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR02-byYh2MM"
      },
      "source": [
        "### CLASSIFICAÇÃO\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Estas métricas são utilizadas em tarefas de classificação, e a maioria delas pode ser adaptada tanto para classificação binária quanto de múltiplas classes. Nas tarefas de classificação buscamos prever qual é a categoria a que uma amostra pertence como, por exemplo, determinar se uma mensagem é spam ou não.\r\n",
        "<br><br>\r\n",
        "***Acurácia (Accuracy/Taxa de Acerto)***<br>\r\n",
        "Esta é a métrica mais simples. É basicamente o número de acertos (positivos) divido pelo número total de exemplos. Ela deve ser usada em datasets com a mesma proporção de exemplos para cada classe.\r\n",
        "\r\n",
        "***F1 Score***<br>\r\n",
        "O F1 Score é uma média harmônica entre precisão e recall. Ela é muito boa quando você possui um dataset com classes desproporcionais, e o seu modelo não emite probabilidades. Isso não significa que não possa ser usada com modelos que emitem probabilidades, tudo depende do objetivo de sua tarefa de machine learning.Em geral, quanto maior o F1 score, melhor.\r\n",
        "<br><br>\r\n",
        "***Precisão (Precision)***<br>\r\n",
        "Número de exemplos classificados como pertencentes a uma classe, que realmente são daquela classe (positivos verdadeiros), dividido pela soma entre este número, e o número de exemplos classificados nesta classe, mas que pertencem a outras (falsos positivos).\r\n",
        "<br><br>\r\n",
        "***Recall***<br>\r\n",
        "Número de exemplos classificados como pertencentes a uma classe, que realmente são daquela classe, dividido pela quantidade total de exemplos que pertencem a esta classe, mesmo que sejam classificados em outra. No caso binário, positivos verdadeiros divididos por total de positivos.\r\n",
        "<br><br>\r\n",
        "***AUC - Area Under the ROC Curve***<br>\r\n",
        "Esta é uma métrica interessante para tarefas com classes desproporcionais. Nela, mede-se a área sob uma curva formada pelo gráfico entre a taxa de exemplos positivos, que realmente são positivos, e a taxa de falsos positivos. Uma das vantagens em relação ao F1 Score, é que ela mede o desempenho do modelo em vários pontos de corte, não necessariamente atribuindo exemplos com probabilidade maior que 50% para a classe positiva, e menor, para a classe negativa. Em sistemas que se interessam apenas pela classe, e não pela probabilidade, ela pode ser utilizada para definir o melhor ponto de corte para atribuir uma ou outra classe a um exemplo. Este ponto de corte normalmente é o ponto que se localiza mais à esquerda, e para o alto, no gráfico, mas depende bastante do custo do erro na previsão de uma determinada classe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vy2C5-3CjCFc"
      },
      "source": [
        "### Regressão\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Na regressão buscamos prever um valor numérico, como, por exemplo, as vendas de uma empresa para o próximo mês. \r\n",
        "<br><br>\r\n",
        "***Mean Squared Error - MSE***<br>\r\n",
        "Talvez seja a mais utilizada, esta função calcula a média dos erros do modelo ao quadrado. Ou seja, diferenças menores têm menos importância, enquanto diferenças maiores recebem mais peso. Existe uma variação, que facilita a interpretação: o Root Mean Squared Error. \r\n",
        "<br><br>\r\n",
        "***Mean Absolute Error - MAE***<br>\r\n",
        "Bastante parecido com MSE, em vez de elevar a diferença entre a previsão do modelo, e o valor real, ao quadrado, ele toma o valor absoluto. Neste caso, em vez de atribuir um peso de acordo com a magnitude da diferença, ele atribui o mesmo peso a todas as diferenças, de maneira linear. \r\n",
        "<br><br>\r\n",
        "***Mean Absolute Percentage Error - MAPE***<br>\r\n",
        "Este erro calcula a média percentual do desvio absoluto entre as previsões e a realidade. É utilizado para avaliar sistemas de previsões de vendas e outros sistemas nos quais a diferença percentual seja mais interpretável, ou mais importante, do que os valores absolutos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLBPPtWr6kqd"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(iris.data,iris.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARWkZupq6mM2"
      },
      "source": [
        "clf.feature_importances_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU1VpVbq6rUW"
      },
      "source": [
        "# underfited: generaliza tudo\n",
        "# good fit: equilibrio entre generalização e decorar = o ideal\n",
        "# overfitted: decora dados\n",
        "\n",
        "iris.data[0]\n",
        "clf.predict([iris.data[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5Cdlu3slPeT"
      },
      "source": [
        "![](https://media.geeksforgeeks.org/wp-content/cdn-uploads/20190523171258/overfitting_2.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaRzQ56N6s2a"
      },
      "source": [
        "# metricas de avaliação\n",
        "\n",
        "from sklearn import metrics\n",
        "pred = clf.predict(iris.data)\n",
        "metrics.accuracy_score(iris.target, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If5asqrT6u0I"
      },
      "source": [
        "# 1.0 = 100% (nada é 100%: esta errado!) \n",
        "# é preciso uma parte do dataset para aprender e a outra parte para testar! imagine voce fazer uma prova com os mesmos exericios estudados: voce vai apenas testar sua memoria, nao a inteligencia\n",
        "\n",
        "clf.fit(iris.data[:120], iris.target[:120])\n",
        "pred = clf.predict(iris.data[120:])\n",
        "metrics.accuracy_score(iris.target[120:], pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bhdp2zt6w1O"
      },
      "source": [
        "# o problema aqui? pegamos apenas os primeiros modelos, a maquina nao entendera ou aprendera como treinar os ultimos, afinal o dataset esta ordenado! 80% esta ok, mas se aparecer um target 2(versicolour) ele nao acertara pois nao aprendeu o que é versicolour!\n",
        "#a maquina aprendeu o que é virginia e setosa, nao versicolour = BALANCEIE OS DADOS!\n",
        "\n",
        "iris.target[120:],pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyyIDS8J6yXe"
      },
      "source": [
        "#validação cruzada é avaliar os dados com ele mesmo = média da validation cross\n",
        "from sklearn.model_selection import cross_val_score\n",
        "score = cross_val_score(clf,iris.data, iris.target, cv=10)\n",
        "#cv é o numero de vezes da validação cruzada! ou seja, ensinou para 90% e treinou em 10%(cv)ele rodou 10x a forma randomica! por default rodaria 3! quanto maior o cv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yfq8z2Pv60IS"
      },
      "source": [
        "import numpy as np\n",
        "np.mean(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJmWQozlkORT"
      },
      "source": [
        "## Diferenças Machine Learning vs. Deep Learning\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "![](https://i.pinimg.com/originals/19/41/9c/19419ca47404d8712f5ac4cd26b58c61.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QItiMc4RUErG"
      },
      "source": [
        "# DEEP LEARNING\n",
        "\n",
        "---\n",
        "\n",
        "![](https://d1m75rqqgidzqn.cloudfront.net/wp-data/2020/04/29165850/April-28-deep-learning-applications-infograph.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smWzGov6WAQG"
      },
      "source": [
        "## Perceptron\n",
        "![](https://d2f0ora2gkri0g.cloudfront.net/dd/db/dddb807b-a15b-457d-a21a-8a9e6f029a3e.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vt20Cu72VRn-"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[:, (2, 3)]  # petal length, petal width\n",
        "y = (iris.target == 0).astype(np.int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrdxYfAEWKTd"
      },
      "source": [
        "# INSTANCIAR PERCEPTRON\n",
        "per_clf = Perceptron(max_iter=100, tol=-np.infty, random_state=42)\n",
        "per_clf.fit(X, y)\n",
        "\n",
        "y_pred = per_clf.predict([[2, 0.5]])\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ-Wru_IVZlm"
      },
      "source": [
        "# VISUALIZAÇÕES\n",
        "a = -per_clf.coef_[0][0] / per_clf.coef_[0][1]\n",
        "b = -per_clf.intercept_ / per_clf.coef_[0][1]\n",
        "\n",
        "axes = [0, 5, 0, 2]\n",
        "\n",
        "x0, x1 = np.meshgrid(\n",
        "        np.linspace(axes[0], axes[1], 500).reshape(-1, 1),\n",
        "        np.linspace(axes[2], axes[3], 200).reshape(-1, 1),\n",
        "    )\n",
        "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
        "y_predict = per_clf.predict(X_new)\n",
        "zz = y_predict.reshape(x0.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\", label=\"Not Iris-Setosa\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"yo\", label=\"Iris-Setosa\")\n",
        "\n",
        "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
        "from matplotlib.colors import ListedColormap\n",
        "custom_cmap = ListedColormap(['#9898ff', '#fafab0'])\n",
        "\n",
        "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
        "plt.xlabel(\"Petal length\", fontsize=14)\n",
        "plt.ylabel(\"Petal width\", fontsize=14)\n",
        "plt.legend(loc=\"lower right\", fontsize=14)\n",
        "plt.axis(axes)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBBRviFR8Fo7"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldJ0No9FsC0M"
      },
      "source": [
        "# NLP/CHATBOT\n",
        "\n",
        "---\n",
        "https://chatterbot.readthedocs.io/en/stable/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vM9EmR1sDkL"
      },
      "source": [
        "!pip install chatterbot\n",
        "!pip install chatterbot_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhyIC_iBsGK7"
      },
      "source": [
        "from chatterbot import ChatBot\n",
        "from chatterbot.trainers import ListTrainer\n",
        "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
        "\n",
        "bot = ChatBot('Pybot')\n",
        "bot = ChatBot(\n",
        "    'Pybot',\n",
        "    storage_adapter='chatterbot.storage.SQLStorageAdapter',\n",
        "    database_uri='sqlite:///database.sqlite3'\n",
        "    )\n",
        "    \n",
        "conversa = ListTrainer(bot)\n",
        "conversa.train([\n",
        "    'Oi?',\n",
        "    'Olá',\n",
        "    'Qual o seu nome?',\n",
        "    'Pybot',\n",
        "    'Prazer em te conhecer',\n",
        "    'Igualmente!',\n",
        "    'Tudo bem?',\n",
        "    'Muito bem e você?',\n",
        "    'Ótimo',\n",
        "    'Papo bom o nosso',\n",
        "    'kkk',\n",
        "    'adeus',\n",
        "    'Volte sempre!',\n",
        "])\n",
        "\n",
        "trainer = ChatterBotCorpusTrainer(bot)\n",
        "trainer.train('chatterbot.corpus.portuguese')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwFZYbWVsISL"
      },
      "source": [
        "while True:\n",
        "  resposta = bot.get_response(input(\"Usuário: \"))\n",
        "  if float(resposta.confidence) > 0.5:\n",
        "      print(\"Pybot: \", resposta)\n",
        "  else:\n",
        "      print(\"Desculpe, eu não entendi!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}